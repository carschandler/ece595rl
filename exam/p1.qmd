## Problem 1

### 1.1

The set of trajectories described is the set of all trajectories such that we
start at $X_0 = 1$ and all following states are either 5, 6, or 7. Because the
transitions between 5, 6, and 7 are periodic, there is no way to return back to
1 once 5 is reached. As a result, we only have to analyze the first step in the
trajectory. If the first step takes us to 5, then the trajectory must belong to
the set described. The probability of transitioning to state 5 from the initial
state, 1, is labeled as $0.5$. If we let $\mathcal{T}$ be the set of
trajectories described in the problem statement, then:

$$
\mathbb{P}(X_1 = 5 | X_0 = 1) = \mathbb{P}(\tau \in \mathcal{T} | X_0 = 1) = 0.5
$$

Where $\tau$ is any trajectory resulting from $X_0 = 1$.

**Final answer**: $0.5$

### 1.2

We can solve this by finding the left eigenvectors of the $\mathbf{P}$ matrix:

```{python}
{{< include p1_2.py >}}
```

The vectors above represeent the stationary distributions of the Markov chain.
We have proven that they are indeed stationary distributions by proving that
they all sum to $1$ and that $\boldsymbol{\bar{\mu}} \mathbf{P} =
\boldsymbol{\bar{\mu}}$ for each vector.

### 1.3

If $\alpha\bar{\boldsymbol{\mu}}^{1} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2}$ is a stationary distribution, then it will satisfy the following properties:

$$
\begin{gathered}
\alpha\bar{\mu}^{1}(s) + (1 - \alpha) \bar{\mu}^{2}(s) \ge 0, \quad \forall s \in \mathcal{S} \\
\sum_{s \in \mathcal{S}} \alpha\bar{\mu}^{1}(s) + (1 - \alpha) \bar{\mu}^{2}(s) = 1 \\
\alpha\bar{\boldsymbol{\mu}}^{1} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} = \left( \alpha\bar{\boldsymbol{\mu}}^{1} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} \right) \mathbf{P}
\end{gathered}
$$

Note that if the quantity above is a convex combination, then both $\alpha$ and $(1-\alpha)$ must be nonnegative, and therefore:

$$
0 \le \alpha \le 1
$$

First we show that for every element $\bar{\mu}_{i}$ of any stationary distribution $\bar{\boldsymbol{\mu}}$:

$$
0 \le \bar{\mu}_{i} \le 1
$$

The left side of the inequality holds by the definition of a stationary distribution, and the right side holds because $\sum_{s \in \mathcal{S}} \bar{\mu}_{i} = 1$ and since each $\bar{\mu}_{i}$ is positive, the maximum value for any one $\bar{\mu}_{i}$ is $1$.

With this in mind, it becomes apparent that the first of the three properties above holds, because if each element of $\mu^{1}, \mu^{2}$ is between $0$ and $1$ and $\alpha$ and $(1-\alpha)$ are also between $0$ and $1$, then we just have a sum of two products of positive values, the result of which will always be positive.

Next:

$$
\begin{aligned}
\sum_{s \in \mathcal{S}} \alpha\bar{\mu}^{1}(s) + (1 - \alpha) \bar{\mu}^{2}(s) \\
= \alpha \sum_{s \in \mathcal{S}} \bar{\mu}^{1}(s) + (1 - \alpha) \sum_{s \in \mathcal{S}} \bar{\mu}^{2}(s)  && \text{by linearity of summation}\\
= \alpha \cdot 1 + (1 - \alpha) \cdot 1  && \text{since } \sum_{s \in \mathcal{S}} \bar{\mu} = 1 \text{ by definition} \\
= 1
\end{aligned}
$$

And finally:

$$
\begin{aligned}
\alpha\bar{\boldsymbol{\mu}}^{1} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} &= \left( \alpha\bar{\boldsymbol{\mu}}^{1} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} \right) \mathbf{P} \\
\alpha\bar{\boldsymbol{\mu}}^{1} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} &= \alpha\bar{\boldsymbol{\mu}}^{1} \mathbf{P} + (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} \mathbf{P} \\
\alpha\bar{\boldsymbol{\mu}}^{1} - \alpha\bar{\boldsymbol{\mu}}^{1} \mathbf{P} &=  (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} \mathbf{P} - (1 - \alpha) \bar{\boldsymbol{\mu}}^{2} \\
\alpha \left(  \bar{\boldsymbol{\mu}}^{1} - \bar{\boldsymbol{\mu}}^{1} \mathbf{P} \right)   &=  (1 - \alpha) \left( \bar{\boldsymbol{\mu}}^{2} \mathbf{P} - \bar{\boldsymbol{\mu}}^{2} \right)  \\
\alpha \left(  \bar{\boldsymbol{\mu}}^{1} - \bar{\boldsymbol{\mu}}^{1} \right)   &=  (1 - \alpha) \left( \bar{\boldsymbol{\mu}}^{2} - \bar{\boldsymbol{\mu}}^{2} \right) &\text{since } \bar{\boldsymbol{\mu}} \mathbf{P} = \bar{\boldsymbol{\mu}}  \text{ by definition}\\
\alpha \cdot 0 &= (1 - \alpha) \cdot 0\\
0 &= 0 & \blacksquare
\end{aligned}
$$

Having proven that the convex combination satisfies all the properties of a
stationary distribution, we have proven that it is itself a stationary
distribution

### 1.4

# TODO: what else can we do with this?

Initializing our chain at $\alpha\mu_{0}^{1} + (1- \alpha) \mu_{0}^{2}$ will cause $\mu_{t}$ to converge to

$$
\alpha\bar{\mu}^{1} + (1- \alpha) \bar{\mu}^{2}
$$

as $t \to \infty$. Intuitively, the pieces of the initial state distribution that were carried to their respective stationary distribution will still be carried to the same distribution, but in proportion based on the fractions $\alpha$ and $(1- \alpha)$.
